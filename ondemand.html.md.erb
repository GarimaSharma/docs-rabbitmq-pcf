---
title: Unlocking the Power of On-Demand RabbitMQ for PCF
owner: London Services
---

## <a id="intro"></a> Introduction

RabbitMQ for PCF v1.10 responds to the demands of PCF platform operators to offer a RabbitMQ on-demand cluster for their application teams, in addition to the existing single-node on-demand plan. The on-demand cluster plan is aimed at workloads that require the same resilience requirements as the Pre-Provisioned offering, but also require their workloads be isolated.  

The platform team can now configure a RabbitMQ for PCF cluster to meet their business requirements, and empower application teams to self-serve their own RabbitMQ cluster. Release 1.10 also provides smoke tests for the on-demand plans so that operations teams can validate the application developer workflow for on-demand services. See [](http://docs-pcf-staging.cfapps.io/rabbitmq-cf/1-10/install-config.html#dedicated_instance_smoke_test_process) 

Platform operators can now offer their application developers three types of RabbitMQ for PCF services: 

* **Pre-provisioned**---For light to moderate messaging needs, this service is fully operated and managed by the platform team as a service.

* **On-demand single node**---For application teams requiring greater isolation than provided by the vHost approach.  Development teams can have full access to their own message broker to adapt the runtime parameters to their requirements.  For more information on these parameters, see [Parameters and Policies](https://www.rabbitmq.com/parameters.html) in the RabbitMQ documentation.  

* **On-demand cluster**---For an increased level of message resilience and cluster availability, as well as the benefits of workload isolation mentioned above. 

## <a id="resources"></a> Managing On-Demand Resources Through Plans

There are a number of operational controls provided to the platform operations team to manage the potential resources consumed by on-demand RabbitMQ:   

* **Control Access**---Operators can choose the development orgs and spaces for which the plans are available and visible.  Each plan is can be enabled or disabled, and service access and visibility can either be organization-wide or enabled per org and space through the command line.<br><br>
	For example, you may decide to enable the single node on-demand plan across all application teams to meet their demand to isolate their workload. You may then choose to offer the on-demand cluster plan only to a subset of application teams who require the extra resources.

* **Set Quotas**---You can set a global quota for all on-demand instances that takes precedence over each plan quota.  This lets you guard against the risk of over-committing resources, but allows the flexibility of over-committing each plan, so you can meet the fluctuating demands your app developers. 

* **Control Resource Consumption**---Each plan offers more fine-grained control over individual plan resource consumption.  At the highest level, you can use the plan quota to control the number of instances that can be deployed within a foundation. For each plan, you can also configure the number of nodes that constitute a cluster (3, 5, or 7), the instance type, and persistent disk storage size to best suit your requirements. 

* **Monitor**---You can monitor the number of instances that have been deployed against the quota you have set so that you can start future resource planning requirements.   
 

## <a id="customizing"></a> Customizing Plan Options 

The RabbitMQ for PCF on-demand plans now expose a number of configuration options that it is important for an operations team to make determinations about so that they are providing the best service to their application developers.  In most instances the defaults that have been pre-selected will meet most application demands.  

### <a id="singlenode"></a> Single Node Plan 

This plan is designed to be simple to configure, deploy and use.  It gives application teams fast access to the power of the leading open source message broker backed by BOSH, to meet all but the most demanding High Availability application messaging requirements.  This can suit high performance workloads requiring messaging resilience and asynchronous messaging replication. RabbitMQ copies messages to disk for resilience, and allows asynchronous messaging replication through the RabbitMQ Federation plug-in.<BR>
========CHECK ACCURACY OF THIS LAST SENTENCE. ALSO WHEN IS THIS PLUGIN AVAILABLE? WE SHOULD NOT MENTION FUTURE PRODUCTS EXCEPT IN A VAGUE WAY... MAYBE DON'T MENTION ASYNCHRONOUS MESSAGE REPLICATION EXCEPT TO SAY "AT A FUTURE DATE, A PLUGIN WILL BE....===========

The plan offers:

* Fast access to an isolated instance of RabbitMQ scoped for the application teams 
* Org and Space Administrator access to the RabbitMQ Management UI so that application teams can have full control over the node
* Updates and upgrades initiated and controlled by operator to keep the instance up to date with the latest security patches and bug fixes 
* Message resilience provided through RabbitMQ exchange or queue federation (post GA)
* Complex topologies enabled through deployment of multiple instances within PCF


#### Plan Configuration 

**Configuration Options** 

* Enable/ Disable plan configuration 
* Determine which organisations and spaces to make the plan available
* Service Instance Quota 
* AZ placement (where applicable)
* The instance (CPU and Memory) and persistent disk (Persisted Message Store) size for the RabbitMQ instance. You should ensure the size of the persistent disk is at least twice as large as the instance memory. 


**Things that are Preconfigured** 

* Metrics are emitted to the firehose for all dedicated instances and the interval is controlled from a single point by the ‘Metrics polling interval’ section of the ‘RabbitMQ’ side tab of Ops Manager.  Due to the impact of some of the cluster settings detailed below, it is strongly recommended that you monitor the metrics exposed and configure alarms as per the KPI documentation. 
* RabbitMQ on-demand instance logs are forwarded using the same configuration as contained in the ‘Syslog’ configuration section of the RabbitMQ for PCF tile. 
* The disk free space limit has been set to be 40% of the RAM of the instance type you select.  So if you selected an instance type with 10GB of RAM, the disk free space limit would be set to 4GB.  Global flow control will be triggered if the amount of free disk space drops below this, and all publishers will be blocked.  Please see [this](https://www.rabbitmq.com/disk-alarms.html)  document for more information
* The memory threshold at which ‘Flow Control’ is triggered is set to 40% of the instance RAM.  Once the alarm is triggered all connections publishing messages will be blocked cluster wide until the alarm is cleared.  For example, if you selected an instance type with 10GB of RAM, once more than 4GB of memory has been used all publishing connections would be blocked. Please see [this](https://www.rabbitmq.com/memory.html) document for more information. 
* The memory paging threshold is the level at which RabbitMQ will try and free up memory by instructing queues to page their contents out to disk, to try and avoid the high watermark being hit and blocking publishers.  This is set to 50% of the configured high watermark (so 20% of configured memory).  For example, if you selected an instance type with 10GB of RAM, once more than 2GB of memory has been used all queues will start writing all queue contents to disk. Please see [this](https://www.rabbitmq.com/memory.html) document for more information. 
 
### <a id="cluster"></a> Cluster Plan

Like the single node plan, this plan is designed to be simple to configure, deploy and use.  It gives application teams fast access to the power of the leading Open Source message broker backed by BOSH, to meet all but the most demanding High Availability application messaging requirements.  This can suit high performance workloads requiring messaging resilience (copied to disk), and asynchronous messaging replication (though the RabbitMQ Federation plugin - post GA). With this plan, however, you also scale out RabbitMQ for PC to multiple nodes.  

This plan offers:

* Fast access to an isolated clustered instance of RabbitMQ scoped to the application teams Organisation and Space 
* Administrator access to the RabbitMQ Management UI for full control over the cluster for the application team.
* Operator initiated and controlled updates and upgrades to keep the instance up to date with latest security patches and bug fixes. 
* Message resilience provided through the ability to mirror queues across RabbitMQ nodes (as well as the option to use Federation and Shovel - post GA) 
* Complex topologies enabled through the deployment of multiple instances within PCF. 


The following are some general principles to be aware of when configuring the cluster plan:

**Designed for Consistency**

RabbitMQ clustering is not primarily a solution for increased availability (see this more detailed description  http://www.rabbitmq.com/distributed.html), instead it is designed for consistency and partition tolerance from the CAP theorem (https://en.wikipedia.org/wiki/CAP_theorem).  RabbitMQ clustering is designed to provide the ability to scale out and enable increased message resilience thorough queue mirroring. Other options such as the use of Federation between exchanges or queues can be used to address this requirement. 

**Number of Nodes**

Because every node in the cluster must maintain a complete database of all metadata, and all changes to the metadata must be confirmed by every node in the cluster, going beyond 7 nodes can have a significant negative impact on performance.  In fact it is recommended that for most workloads 3 nodes will provide optimum resilience and performance. 

**Network Latency**

RabbitMQ clusters are only recommended to be deployed in low latency networks, which normally means that it is not advisable to deploy across availability zones.  The stability and performance of the RabbitMQ cluster is heavily influenced by the workload being run on the nodes, replication choices and network latency.  

For this reason, Pivotal that RabbitMQ clusters are deployed into a single Ops Manager Availability Zone.  However, where different availability zones are within the same datacenter with reliable low latency links, spanning Availability Zones could be used.  For cloud IaaS deployments it is not recommended that deployments span ‘Regions’.  

For example, in Amazon Web Services (AWS) terms (http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/RegionsAndAZs.html), deploying a RabbitMQ cluster across Availabilty Zones within a region should provide high enough network performance to prevent impact cluster stability.  However, deploying across AWS ‘Regions’ will likely lead to cluster instability.  

#### The consistency or availability tradeoff 

In a distributed messaging system a tradeoff must be made between availability or consistency when a network partition event occurs and one or more nodes are not able to communicate with each other.  The cluster plan allows Operators to make a choice about how they want the deployed RabbitMQ cluster to react in the event of a network partition.  

It is recommended that in the majority of cases keeping the default cluster partition option of ‘pause\_minority’ will satisfy most use cases.  A detailed discussion of the benefits of each option are discussed here (https://www.rabbitmq.com/partitions.html), but currently only ‘pause_minority’ and ‘autoheal’ can be chosen.  Choosing the ‘pause\_minoirty’ partition handling strategy will favour message consistency over availability, which is what most customers should choose.  A more detailed description of the options available in RabbitMQ for PCF can be found here (https://docs.pivotal.io/rabbitmq-cf/1-8/partitions.html). 

For example, if you create a RabbitMQ cluster with three nodes and one node becomes unable to communicate with the other two nodes (a full network partition) then the node that is in the minority (it cannot communicate with the other two nodes) will pause and the other two nodes will continue serving traffic.  Should each node loose connectivity with the other two, then the entire cluster will be paused to preserve data as no majority can be established.  The cluster will ‘heal’ when two or more nodes are able to communicate with each other. 

#### RabbitMQ Queue Availability

It is important to be aware that in the discussion above we have focused on the RabbitMQ clusters availability and its ability to respond correctly to requests.  Cluster availability does not mean that all of the messages within the queues are also available.  By default, queues within a RabbitMQ cluster are located on a single node (the node on which they were first declared). Queues can be configured to mirror across multiple nodes, and any message published to the queue is replicated to all mirrors.  Enabling mirroring can have a negative impact on queue performance as messages must be copied to all mirrors before being acknowledged. 

Each mirrored queue consists of one master and one or more mirrors, with the oldest mirror being promoted to the new master if the old master disappears for any reason.  Consumers are connected to the master regardless of which node they connect to, with mirrors dropping messages that have been acknowledged at the master. Queue mirroring therefore enhances availability, but does not distribute load across nodes (all participating nodes each do all the work).

Application developers must decide if they want to use queue mirroring and the policy that they want to apply to their queues (https://www.rabbitmq.com/ha.html) as their choices will have significant impact on the availability of their queue.  

Unlike the Pre-provisioned plan we do not ship the cluster with a default load balancer, and so developers will need to account for the fact that they will need to configure their application to use the array of hosts provided in VCAP_SERVICES.  Applications will also need to ensure that they have re-try logic and reconnection logic that will iterate over the range of hosts provided if they have enabled queue mirroring.  Most common RabbitMQ clients have this logic built into them (i.e. Spring AMQP https://docs.spring.io/spring-amqp/reference/htmlsingle/#auto-recovery).

As the cluster plan has been created to enable Application teams to self-serve, not having a load balancer in front of the RabbitMQ cluster can confer the following benefits: 

* Manage resources better (fewer vms)
* Help with troubleshooting : client IP will now be the IP of the source container and not HAproxy
* Reduce the number of hops (latency) between apps and broker 
* Enable deterministic queue placement; for larger scale deployments it makes less sense not to be able to control queue placement 
* Empower application teams to manage their cluster in the best way for their application 
* Make more explicit that re-try logic is required in an application if it requires HA access to a queue (all nodes can route a queue if it is available) 

#### Plan Configuration 


Configuration Options: 

* Enable/ Disable plan configuration 
* Determine which organisations and spaces to make the plan available 
* Service instance quota
* Number of nodes (3,5 or 7) 
* Network Partition behaviour (see notes above)
* AZ placement (See notes above)
* The instance (CPU and Memory) and persistent disk (Persisted Message Store) size for the RabbitMQ instance. You should ensure the size of the persistent disk is at least twice as large as the instance memory. 


Things that are preconfigured: 

* Metrics are emitted to the firehose for all dedicated instances and the interval is controlled from a single point by the ‘Metrics polling interval’ section of the ‘RabbitMQ’ side tab of Ops Manager.  Due to the impact of some of the cluster settings detailed below, it is strongly recommended that you monitor the metrics exposed and configure alarms as per the KPI documentation. 
* RabbitMQ on-demand instance logs are forwarded using the same configuration as contained in the ‘Syslog’ configuration section of the RabbitMQ for PCF tile. 
* The disk free space limit has been set to be 40% of the RAM of the instance type you select.  So if you selected an instance type with 10GB of RAM, the disk free space limit would be set to 4GB.  Global flow control will be triggered if the amount of free disk space drops below this, and all publishers will be blocked.  Please see [this](https://www.rabbitmq.com/disk-alarms.html)  document for more information
* The memory threshold at which ‘Flow Control’ is triggered is set to 40% of the instance RAM.  Once the alarm is triggered all connections publishing messages will be blocked cluster wide until the alarm is cleared.  For example, if you selected an instance type with 10GB of RAM, once more than 4GB of memory has been used all publishing connections would be blocked. Please see [this](https://www.rabbitmq.com/memory.html) document for more information. 
* The memory paging threshold is the level at which RabbitMQ will try and free up memory by instructing queues to page their contents out to disk, to try and avoid the high watermark being hit and blocking publishers.  This is set to 50% of the configured high watermark (so 20% of configured memory).  For example, if you selected an instance type with 10GB of RAM, once more than 2GB of memory has been used all queues will start writing all queue contents to disk. Please see [this](https://www.rabbitmq.com/memory.html) document for more information. 




### <a id="general"></a> General Considerations for On-Demand RabbitMQ Clusters

* It is important to monitor the number of instances that have been deployed vs the quota that has been set via the metric exposed on the CF Firehose. 

* Each instance is pre-configured to emit metrics to the CF Firehose, and can be identified by the ‘deployment’ tag, which will have the service instance id.   It is important to monitor these metrics as per the KPI information listed here (https://docs.pivotal.io/rabbitmq-cf/1-8/monitor.html)


