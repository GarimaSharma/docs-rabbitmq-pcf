---
title: Unlocking the Power of On-Demand RabbitMQ for PCF
owner: London Services
---

## <a id="intro"></a> Introduction

RabbitMQ for Pivotal Cloud Foundry (PCF) v1.10 responds to the demands of PCF platform operators to offer a RabbitMQ on-demand cluster for their application teams, in addition to the existing single-node on-demand plan. The on-demand cluster plan is aimed at workloads that require the same resilience requirements as the Pre-Provisioned offering, but also require their workloads be isolated.  

The platform team can now configure a RabbitMQ for PCF cluster to meet their business requirements, and empower application teams to self-serve their own RabbitMQ cluster. Release 1.10 also provides smoke tests for the on-demand plans so that operations teams can validate the application developer workflow for on-demand services. See [](http://docs-pcf-staging.cfapps.io/rabbitmq-cf/1-10/install-config.html#dedicated_instance_smoke_test_process) 

Platform operators can now offer their application developers three types of RabbitMQ for PCF services: 

* **Pre-provisioned**---For light to moderate messaging needs, this service is fully operated and managed by the platform team as a service.

* **On-demand single node**---For application teams requiring greater isolation than provided by the vHost approach.  Development teams can have full access to their own message broker to adapt the runtime parameters to their requirements.  For more information on these parameters, see [Parameters and Policies](https://www.rabbitmq.com/parameters.html) in the RabbitMQ documentation.  

* **On-demand cluster**---For an increased level of message resilience and cluster availability, as well as the benefits of workload isolation mentioned above. 

This topic explains how to benefit from the on-demand plans. 

For information about the pre-provisioned plan, see [Deploying the RabbitMQ Pre-Provisioned Service](./deploying.html). For information on using pre-provisioned plans to isolate workloads, see [Creating Isolation with the Tile Replicator](./replicator.html).


## <a id="singlenode"></a> On-Demand Single Node Plan 

This plan is designed to be simple to configure, deploy, and use.  It gives application teams fast access to the power of the leading open source message broker backed by BOSH, to meet all but the most demanding High Availability application messaging requirements.  

This plan can suit high-performance workloads requiring messaging resilience and asynchronous messaging replication. RabbitMQ copies messages to disk for resilience, and allows asynchronous messaging replication through the RabbitMQ Federation plug-in.<br><br>==========<br>CHECK ACCURACY OF THE LAST SENTENCE ABOVE. ALSO WHEN IS THIS PLUGIN AVAILABLE? WE SHOULD NOT MENTION FUTURE PRODUCTS EXCEPT IN A VAGUE WAY... MAYBE DON'T MENTION ASYNCHRONOUS MESSAGE REPLICATION EXCEPT TO SAY "AT A FUTURE DATE, A PLUGIN WILL BE...."<br>===========

This plan offers:

* Fast access to an isolated instance of RabbitMQ scoped for the application teams 
* Org and Space Administrator access to the RabbitMQ Management UI so application teams can have full control over the node
* Updates and upgrades initiated and controlled by the operator to keep the instance up to date with the latest security patches and bug fixes 
* Message resilience provided through RabbitMQ exchange or queue federation (post GA)
* Complex topologies enabled through deployment of multiple instances within PCF


## <a id="cluster"></a> On-Demand Cluster Plan

Like the single node plan, this plan is designed to be simple to configure, deploy and use.  It gives application teams fast access to the power of the leading Open Source message broker backed by BOSH, to meet all but the most demanding High Availability application messaging requirements.  

This plan can suit high performance workloads requiring messaging resilience (copied to disk), and asynchronous messaging replication (though the RabbitMQ Federation plugin - post GA). With this plan, however, you also scale out RabbitMQ for PC to multiple nodes.  

This plan offers:

* Fast access to an isolated clustered instance of RabbitMQ scoped to the application team Orgs and Spaces 
* Administrator access to the RabbitMQ Management UI to give application teams full control over the cluster
* Updates and upgrades initiated and controlled by the operator to keep the instance up to date with the latest security patches and bug fixes. 
* Message resilience provided through the ability to mirror queues across RabbitMQ nodes (as well as the option to use Federation and Shovel - available at a future date) 
* Complex topologies enabled through deployment of multiple instances within PCF 


The following are some general principles to be aware of when configuring the cluster plan:

**Designed for Consistency**

RabbitMQ clustering is not primarily a solution for increased availability. Instead, it is designed for consistency and partition tolerance, as described in the [CAP theorem](https://en.wikipedia.org/wiki/CAP_theorem). RabbitMQ clustering provides increased message consistency through queue mirroring. This means that messages accessed in one queue are exactly the same as in another queue. For more detailed information, see [The Consistency or Availability Tradeoff](#tradeoff).

Other options can be used for availability requirements, such as the use of federation between exchanges or queues. 

For a more detailed description of distributed RabbitMQ brokers, see the [RabbitMQ documentation](http://www.rabbitmq.com/distributed.html).

**Number of Nodes**

Every node in the on-demand cluster maintains a complete database of all metadata, and all changes to the metadata are confirmed by every node in the cluster. Therefore, going beyond 7 nodes can have a significant negative impact on performance. For optimum resilience and performance, Pivotal recommends 3 nodes for most workloads. 

**Network Latency**

RabbitMQ clusters are only recommended for deployment in low latency networks, which normally means that it is not advisable to deploy these clusters across availability zones (AZs). The stability and performance of the RabbitMQ cluster is heavily influenced by the workload on the nodes, replication choices, and network latency.  

For this reason, Pivotal recommends that RabbitMQ clusters are deployed into a single Ops Manager AZ.  However, where different AZs are in the same datacenter, with reliable low latency links, spanning AZs could be used.  

For cloud IaaS deployments, Pivotal does not recommend that deployments span *regions*. For example, in Amazon Web Services (AWS) terms, deploying a RabbitMQ cluster across AZs within a region should provide high enough network performance to prevent impacting cluster stability.  However, deploying across AWS regions will likely lead to cluster instability. For more information, see the [AWS documentation](http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/RegionsAndAZs.html).

### <a id="tradeoff"></a> The Consistency or Availability Tradeoff 

In a distributed messaging system, a tradeoff must be made between availability or consistency when a network partition event occurs, and one or more nodes are not able to communicate with each other.  The cluster plan lets operators decide how they want the RabbitMQ cluster to react in the event of a network partition.  

Pivotal recommends keeping the default cluster partition option of `pause_minority` since this will satisfy most use cases.  Choosing the `pause_minoirty` partition-handling strategy favors message consistency over availability. A detailed discussion of the benefits of the possible options are discussed the [RabbitMQ documentation](https://www.rabbitmq.com/partitions.html). For a more detailed description of the options available in RabbitMQ for PCF see [Clustering and Network Partitions](./partitions.html). 

Here is an example of how `pause_minority` works. If you create a RabbitMQ cluster with three nodes and one node becomes unable to communicate with the other two, this node is in the minority. The node that is in the minority is paused, and the other two nodes continue serving traffic.  If each of the nodes loses connectivity with the other two, then the entire cluster is paused to preserve data since no majority can be established. The cluster *heals* when two or more nodes are able to communicate with each other. 

### <a id="queues"></a> RabbitMQ Queue Availability

It is important to be aware that message queue availability is different from cluster availability, so having cluster availability does not mean that all of the messages within the queues are also available.  

By default, queues within a RabbitMQ cluster are located on a single node---the node on which they were first declared. However, queues can be configured to mirror across multiple nodes, so that any message published to the queue is replicated to all mirrors.  Enabling mirroring can have a negative impact on queue performance since messages must be copied to all mirrors before being acknowledged. 

Each mirrored queue consists of one master and one or more mirrors, with the oldest mirror being promoted to the new master if the old master disappears for any reason.  Consumers are connected to the master regardless of which node they connect to, and mirrors drop messages that have been acknowledged at the master. Queue mirroring enhances queue availability, but does not distribute load across nodes since each of the participating nodes must still do all the work.

App developers must decide if they want to use queue mirroring and determine the policy they want to apply to their queues. These choices have significant impact on the availability of their queues. For more information, see the [RabbitMQ documentation](https://www.rabbitmq.com/ha.html).

Unlike the pre-provisioned plan, the cluster plan does not ship with a default load balancer. Therefore, developers must configure their application to use the array of hosts provided in `VCAP_SERVICES`. If developers enable queue mirroring, they must also ensure their applications have re-try logic, and reconnection logic that iterates over the range of hosts provided.  Most common RabbitMQ clients have this logic built into them. For more information, see the [Spring AMQP documentation](https://docs.spring.io/spring-amqp/reference/htmlsingle/#auto-recovery).

Since the cluster plan is designed to enable application teams to self-serve, not having a load balancer in front of the RabbitMQ cluster has these benefits: 

* Manage resources better, as fewer VMs are needed.
* Help with troubleshooting. Client IP is now the IP of the source container and not the HAproxy.
* Reduce the number of hops between apps and broker. This helps with latency.
* Determine queue placement. This makes sense for larger scale deployments. 
* Empower application teams to manage their cluster in the best way for their application. 
* Require re-try logic in an application if it needs HA access to a queue. Thus, all nodes can route to a queue if it is available. 

## <a id="resources"></a> Managing On-Demand Resources Through Plans

In configuring each plan, there are a number of operational controls that platform operations teams can use to manage the resources consumed by on-demand RabbitMQ:   

* **Control Access**---Operators can choose the development orgs and spaces for which the plans are available and visible.  Each plan can be enabled or disabled, and service access and visibility can either be global, or enabled per org and space through the command line.<br><br>
	For example, you may decide to enable the single node on-demand plan across all application teams to meet their demand to isolate their workload. You may then choose to offer the on-demand cluster plan only to a subset of application teams who require the extra resources.

* **Set Quotas**---You can set a global quota for all on-demand instances that takes precedence over each plan quota.  This lets you guard against the risk of over-committing resources, but allows the flexibility of over-committing each plan, so you can meet the fluctuating demands of your app developers. 

* **Control Resource Consumption**---Each plan offers more fine-grained control over individual plan resource consumption.  At the highest level, you can use the plan quota to control the number of instances that can be deployed within a foundation. For each plan, you can also configure the number of nodes that constitute a cluster (3, 5, or 7), the instance type, and persistent disk storage size to best suit your requirements. 

* **Monitor**---You can monitor the number of instances that have been deployed against the quota you have set so that you can start future resource planning requirements.  
 

## <a id="customizing"></a> Customizing Plan Options 

The RabbitMQ for PCF on-demand plans expose a number of configuration options. In most cases the default configurations meet most application demands. However, it is important for an operations team to consider the options to ensure that they provide the best service to their app developers. This section explains these options.   


### <a id="configoptions"></a> Configuration Options 

#### Single Node and Cluster Plans

* Enable/ Disable plan 
* Determine which orgs and spaces can see and access the plan
* Set Service Instance Quota 
* Select AZ placement (where applicable)
* Set RabbitMQ instance size (CPU and Memory)
* Set persistent disk size (Persisted Message Store) for the RabbitMQ instance. Ensure the size of the persistent disk is at least twice as large as the instance memory. 

#### Cluster Plan Only

* Set number of nodes to 3, 5, or 7
* Determine network partition behavior (see notes [above](#tradeoff))


### <a id="preconfigurd"></a> Things that are Preconfigured 

The following is pre-configured for both the single node and the cluster plans:

* **Metrics**---Emitted to the firehose for all on-demand instances. The polling interval is set in the Ops Manager, in the **Metrics polling interval** field, in the **RabbitMQ** tab of the RabbitMQ for PCF tile.  Due to the impact of some of the cluster settings detailed below, Pivotal strongly recommends that you monitor the exposed metrics and configure alarms as recommended in [Monitoring and KPIs for On-Demand RabbitMQ for PCF](./monitor.html#kpi).See also [Monitoring On-Demand RabbitMQ Clusters](#monitor-clusters) below.

* **Logs**---RabbitMQ on-demand instance logs are forwarded using the same configuration as contained in the **Syslog** tab of the RabbitMQ for PCF tile. 

* **Disk free space limit**---Set to 40% of the RAM of the instance type you select. For example, if you select an instance type with 10GB of RAM, the disk free space limit is set to 4GB.  Global flow control is triggered if the amount of free disk space drops below this, and all publishers are blocked.  For more information, see [Disk Alarms](https://www.rabbitmq.com/disk-alarms.html) in the RabbitMQ documentation.

* **Memory threshold for triggering flow control**---Threshold at which flow control is triggered is set to 40% of the instance RAM. This means that once the alarm is triggered, all connections publishing messages are blocked cluster-wide until the alarm is cleared.  <br><br>For example, if you select an instance type with 10GB of RAM, once more than 4GB of memory is used, all publishing connections are blocked. For more information, see [Memory Alarms](https://www.rabbitmq.com/memory.html) in the RabbitMQ documentation. 

* **Memory paging threshold**---This is the level at which RabbitMQ tries to free up memory by instructing queues to page their contents out to disk. This is done to try to avoid reaching the high watermark and blocking publishers.  This threshold is set to 50% of the configured high watermark, which is 20% of configured memory. <br><br>==========<br>REGARDING '20% OF CONFIGURED MEMORY' STATEMENT ABOVE.... I DON'T THINK THERE'S A REFERENCE TO THIS ELSEWHERE... SHOULD WE SAY IN THE "CONFIGURATION OPTIONS" BULLET LIST ABOVE THIS, THAT YOU SHOULD CONFIGURE 'MEMORY' TO BE 40% OF THE HIGH WATERMARK?<br>============<br><br>For example, if you select an instance type with 10GB of RAM, once more than 2GB of memory is used, all queues start writing all queue contents to disk. For more information, see the [RabbitMQ documentation](https://www.rabbitmq.com/memory.html). 

#### <a id="monitor-clusters"></a> Monitoring On-Demand RabbitMQ Clusters

* It is important to monitor and compare the number of instances that have been deployed against the quota you set via the metric exposed on the CF Firehose. 

* Each instance is pre-configured to emit metrics to the CF Firehose, and can be identified by the `deployment` tag, which has the service instance ID. It is important to monitor these metrics as recommended in [Monitoring and KPIs for On-Demand RabbitMQ for PCF](./monitor.html#kpi).
